Конечно, вот пример консольного приложения на Python, которое использует пакет multiprocessing для параллельной загрузки изображений из списка URL-адресов. Для этого примера мы будем использовать библиотеку requests для выполнения HTTP-запросов.

```python
import os
import argparse
import requests
import multiprocessing

def download_image(url):
response = requests.get(url, stream=True)
if response.status_code == 200:
filename = os.path.basename(url)
with open(filename, "wb") as file:
for chunk in response.iter_content(1024):
file.write(chunk)
print(f"Image downloaded: {filename}")


if __name__ == "__main__":
parser = argparse.ArgumentParser(description="Parallel Image Downloader")
parser.add_argument("urls", metavar="URL", type=str, nargs="+", help="List of image URLs")
args = parser.parse_args()

urls = args.urls

processes = []
for url in urls:
process = multiprocessing.Process(target=download_image, args=(url,))
processes.append(process)
process.start()

for process in processes:
process.join()

print("Images downloaded successfully.")
```

Вы можете сохранить этот код в файл с расширением `.py`, например, `image_downloader.py`. Затем вы можете запустить приложение из командной строки, указав список URL-адресов в качестве аргументов командной строки.

Пример использования:
```
python image_downloader.py https://example.com/image1.jpg https://example.com/image2.jpg https://example.com/image3.jpg
```

Приложение начнет загрузку изображений из указанных URL-адресов, используя несколько процессов для ускорения процесса. Загруженные изображения будут сохранены в текущей директории с их исходными именами файлов.